\chapter{Linear Algebra}

\section{Matrix Basics}

\begin{definition}[Matrix]
    A $(n \times m)$-dimension matrix $A$ has $n$ rows and $m$ columns, and each of its entries $a_{j, k}$, for $1 \le j \le n$ and $1 \le k \le m$ are denoted as
    \begin{equation}
        A = \begin{bmatrix}
            a_{1, 1} & a_{1, 2} & \dots  & a_{1, m} \\
            a_{2, 1} & a_{2, 2} & \dots  & a_{2, m} \\
            \vdots   & \vdots   & \ddots & \vdots   \\
            a_{n, 1} & a_{n, 2} & \dots & a_{n, m} \\
        \end{bmatrix}
    \end{equation}
\end{definition}

\begin{definition}[Set of Matrices of Dimension $n \times m$]
    Let $\MatrixClass{n}{m}$ denote the set of all matrices with dimension $n \times m$, that is, having $n$ rows and $m$ columns.
\end{definition}

\begin{definition}[Square Matrix]
    A \textit{square matrix} is a matrix with dimension $n \times n$.
\end{definition}

\begin{definition}[Matrix Addition]
    Let $A, B \in \MatrixClass{n}{m}$ be two matrices of the same dimension $n \times m$. Then the sum matrix $C = A + B$ is defined to have entries
    \begin{equation}
        c_{j, k} = a_{j, k} + b_{j, k}
    \end{equation}
    
    That is,
    \begin{equation}
        \begin{split}
            \begin{bmatrix}
                a_{1, 1} & a_{1, 2} & \dots  & a_{1, m} \\
                a_{2, 1} & a_{2, 2} & \dots  & a_{2, m} \\
                \vdots   & \vdots   & \ddots & \vdots   \\
                a_{n, 1} & a_{n, 2} & \dots & a_{n, m} \\
            \end{bmatrix} 
            + 
            \begin{bmatrix}
                b_{1, 1} & b_{1, 2} & \dots  & b_{1, m} \\
                b_{2, 1} & b_{2, 2} & \dots  & b_{2, m} \\
                \vdots   & \vdots   & \ddots & \vdots   \\
                b_{n, 1} & b_{n, 2} & \dots & b_{n, m} \\
            \end{bmatrix} \\
            \coloneqq
            \begin{bmatrix}
                a_{1, 1} + b_{1, 1} & a_{1, 2} + b_{1, 2} & \dots & a_{1, m} + b_{1, m} \\
                a_{2, 1} + b_{2, 1} & a_{2, 2} + b_{2, 2} & \dots & a_{2, m} + b_{2, m} \\
                \vdots   & \vdots   & \ddots & \vdots   \\
                a_{n, 1} + b_{n, 1} & a_{n, 2} + b_{n, 2} & \dots & a_{n, m} + b_{n, m} \\
            \end{bmatrix}
        \end{split}
    \end{equation}
\end{definition}

\begin{definition}[Matrix Multiplication]
    Let $A$ be an $(l \times m)$ matrix and $B$ be an $(m \times n)$ matrix. Then their product $C = A \cdot B$ is the $(l \times n)$ matrix where each entry $c_{j, k}$ is
    \begin{equation}
        c_{j, k} \coloneqq \sum\limits^{m}_{s = 1} a_{j, s} b_{s, k}
    \end{equation}
    
    Note that matrix multiplication is \textit{not commutative}, that is, for most cases $A \cdot B \ne B \cdot A$
\end{definition}

\begin{definition}[Identity Matrix]
    Let $I_n$ denote the \textit{identity} matrix with dimension $n \times n$
    \begin{equation}
        I_n \coloneqq \begin{bmatrix}
            1      & 0      & \cdots & 0      \\
            0      & 1      & \cdots & 0      \\
            \vdots & \vdots & \ddots & \vdots \\
            0      & 0      & \cdots & 1      \\
        \end{bmatrix}
    \end{equation}
    
    Notice that all diagonal entries $i_{j, k}$ with indices $j = k$ is $1$, while all other entries are $0$.
    
    Alternatively, the \textit{identity} matrix can be defined with entries $\delta_{j, k}$ where $\delta$ is the \textit{Kronecker symbol} such that
    \begin{equation}
        \delta_{j, k} \coloneqq \begin{cases}
            1 & j = k \\
            0 & j \ne k
        \end{cases}
    \end{equation}
\end{definition}

\begin{definition}[Matrix Multiplication by Scalar $\lambda$]
    Let $\lambda \in \Real$ be a constant, then the multiplication of an $(n \times m)$-dimension matrix $A$ by $\lambda$ is defined as
    \begin{equation}
        \lambda A \coloneqq \begin{bmatrix}
            \lambda a_{1, 1} & \lambda a_{1, 2} & \cdots & \lambda a_{1, m} \\
            \lambda a_{2, 1} & \lambda a_{2, 2} & \cdots & \lambda a_{2, m} \\
            \vdots           & \vdots           & \ddots & \vdots \\
            \lambda a_{n, 1} & \lambda a_{n, 2} & \cdots & \lambda a_{n, m} \\
        \end{bmatrix}
    \end{equation}
    
    If the dimension of $A$ is $n \times n$, i.e. $A$ is a \textit{square matrix}, then $\lambda A$ is equivalently
    \begin{equation}
        \lambda A \coloneqq
        \begin{bmatrix}
            \lambda & 0       & \cdots & 0       \\
            0       & \lambda & \cdots & 0       \\
            \vdots  & \vdots  & \ddots & \vdots  \\
            0       & 0       & \cdots & \lambda \\
        \end{bmatrix}
        \begin{bmatrix}
            a_{1, 1} & a_{1, 2} & \dots  & a_{1, n} \\
            a_{2, 1} & a_{2, 2} & \dots  & a_{2, n} \\
            \vdots   & \vdots   & \ddots & \vdots   \\
            a_{n, 1} & a_{n, 2} & \dots  & a_{n, n} \\
        \end{bmatrix}
    \end{equation}
\end{definition}

\begin{lemma}
    If $A$ is a matrix with dimension $n \times n$, $A$ is a \textit{square} matrix, then
    \begin{equation}
        A I \equiv I A \equiv A
    \end{equation}
    Where $I$ is the \textit{identity} matrix with dimension $n \times n$.
\end{lemma}

\begin{proof}
    Let $B = AI$, then
    \begin{equation}
        b_{j, k} = \sum\limits^{n}_{s = 1} a_{j, s} \delta_{s, k}
    \end{equation}
    Only $\delta_{k, k}$ is non-zero, thus $b_{j, k} = a_{j, k}$. The same is true for $IA$.
\end{proof}

\subsection{Matrix Addition and Multiplication Properties}

\begin{proposition}[Associative Matrix Multiplication]
    Given matrices $A \in \MatrixClass{n}{m}, B \in \MatrixClass{m}{p}$ and $C \in \MatrixClass{p}{q}$ then
    \begin{equation}
        (A B) C \equiv A (B C)
    \end{equation}
\end{proposition}

\begin{proof}
    The entry $t_{j, l}$ of $T = (A B) C$ is
    \begin{equation}
        t_{j, l} = \sum^{p}_{k = 1} \left( \sum^{m}_{s = 1} a_{j, s} b_{s, k} \right) c_{k, l} \equiv \sum^{p}_{k = 1} a_{j, s} \left( \sum^{m}_{s = 1} b_{s, k} c_{k, l} \right) = u_{j, l}
    \end{equation}
    Where $u_{j, l}$ are entries of the matrix $U = A (B C)$
\end{proof}

\begin{proposition}[Distributive Matrix Multiplication]
    Given matrices $A \in \MatrixClass{n}{m}, B \in \MatrixClass{m}{p}$ and $C \in \MatrixClass{p}{q}$ then
    \begin{align}
        A (B + C) &= A B + A C \\
        (A + B) C &= A C + B C
    \end{align}
\end{proposition}

\begin{proof}
    Let $S = A (B + C)$ and $E = A B + A B$, then each entry $s_{j, l}$ from $S$ is
    \begin{equation}
        s_{j, l} = \sum\limits^{m}_{s = 1} a_{j, s} ( b_{s, l} + c_{s, l} ) \equiv \sum\limits^{m}_{s = 1} a_{j, s} b_{s, l} + \sum\limits^{m}_{s = 1} a_{j, s} c_{s, l} = e_{j, l}
    \end{equation}
    Where $e_{j, l}$ are entries from $E$.
    
    Let $T = (A + B) C$ and $F = A C + B C$, then each entry $t_{j, l}$ from $T$ is
    \begin{equation}
        t_{j, l} = \sum\limits^{m}_{s = 1} (a_{j, s} + b_{s, l}) c_{s, l}\equiv \sum\limits^{m}_{s = 1} a_{j, s} c_{s, l} + \sum\limits^{m}_{s = 1} b_{j, s} c_{s, l} = f_{j, l}
    \end{equation}
    Where $f_{j, l}$ are entries from $F$.
\end{proof}

\subsection{Determinant of a Square Matrix}

\begin{definition}[Determinant of a $2 \times 2$ Matrix]
    Given a $2 \times 2$ \textit{square} matrix $A \in \MatrixClass{2}{2}$
    \begin{equation}
        A = \begin{bmatrix}
            a & b \\
            c & d
        \end{bmatrix}
    \end{equation}
    Then the determinant of $A$, denoted $\det(A)$ or $\VSBars{A}$ is calculated with
    \begin{equation}
        \det(A) = 
        \left\vert
        \begin{bmatrix}
            a & b \\
            c & d
        \end{bmatrix}
        \right\vert
        =
        a d - b c
    \end{equation}
\end{definition}

\begin{definition}[Determinant of a $3 \times 3$ Matrix]
    Given a $3 \times 3$ \textit{square} matrix $A \in \MatrixClass{3}{3}$
    \begin{equation}
        A = \begin{bmatrix}
            a & b & c \\
            d & e & f \\
            g & h & i
        \end{bmatrix}
    \end{equation}
    Then the determinant of $A$, denoted $\det(A)$ or $\VSBars{A}$ is calculated with
    \begin{align}
        \det(A) = 
        \left\vert
        \begin{matrix}
            a & b & c \\
            d & e & f \\
            g & h & i
        \end{matrix}
        \right\vert
        &=
        a
        \left\vert
        \begin{matrix}
            \square & \square & \square \\
            \square & e       & f       \\
            \square & h       & i
        \end{matrix}
        \right\vert
        - b
        \left\vert
        \begin{matrix}
            \square & \square & \square \\
            d       & \square & f       \\
            g       & \square & i
        \end{matrix}
        \right\vert
        + c
        \left\vert
        \begin{matrix}
            \square & \square & \square \\
            d       & e       & \square \\
            g       & h       & \square
        \end{matrix} 
        \right\vert \\
        &=
        a
        \left\vert
        \begin{matrix}
            e & f \\
            h & i
        \end{matrix}        
        \right\vert
        - b
        \left\vert
        \begin{matrix}
            d & f \\
            g & i
        \end{matrix}        
        \right\vert
        + c
        \left\vert
        \begin{matrix}
            d & e \\
            g & h
        \end{matrix}        
        \right\vert \\
        &=
        aei - afh + bfg - bdi + cdh - ceg 
    \end{align}
\end{definition}

\begin{definition}[Upper Triangular Matrix]
    An $n \times n$ matrix $A \in \MatrixClass{n}{n}$ is called a \textit{upper triangular} (or \textit{right triangular}) matrix if it has the form
    \begin{equation}
        A = \begin{bmatrix}
            a_{1, 1} & a_{1, 2} & \cdots & a_{1, n} \\
                     & a_{2, 2} & \cdots & a_{2, n} \\
                     &          & \ddots & \vdots   \\
            0        &          &        & a_{n, n} \\
        \end{bmatrix}
    \end{equation}
    Where all the lower triangular part are $0$s.
\end{definition}

\begin{lemma}[Determinant of an Upper Triangular Matrix]
    Given an $n \times n$ \textit{upper triangular} matrix $A$, then its \textit{determinant} $\det(A)$ can be calculated as
    \begin{equation}
        \det(A) =
        \left\vert
        \begin{matrix}
            \gamma_1 & \ast     & \ast     & \cdots  & \ast     \\
            \vdots   & \gamma_2 & \ast     & \rddots & \vdots   \\
            \vdots   & \cdots   & \gamma_3 & \ast    & \ast     \\
            \vdots   & \rddots  & \vdots   & \ddots  & \ast     \\
            0        & \cdots   & \cdots   & \cdots  & \gamma_n 
        \end{matrix}
        \right\vert
        =
        \gamma_1 \gamma_2 \cdots \gamma_n
    \end{equation}
    
    Where $\ast$ represents arbitrary entries.
\end{lemma}

\begin{corollary}
    A specialization of this lemma is the case for $3 \times 3$ \textit{upper triangular} matrix $A$:
    \begin{equation}
        \det(A) =
        \left\vert
        \begin{matrix}
            \gamma_1 & \ast & \ast \\
            0        & a    & b    \\
            0        & c    & d
        \end{matrix}        
        \right\vert
        =
        \left\vert
        \begin{matrix}
            \gamma_1 & \ast & \ast                    \\
            0        & a    & b                       \\
            0        & 0    & d - b \cdot \frac{c}{a}
        \end{matrix}        
        \right\vert
        =
        \gamma_1 (a d - b c)
    \end{equation}
\end{corollary}

\section{Solving Linear System of Equations}

\begin{definition}
    Matrices are useful for solving a \textit{linear system of equations} of the form
    \begin{equation}
        \left\{
        \begin{array}{c c}
            a_{1, 1} x_1 + a{1, 2} x_2 + \cdots + a_{1, n} x_n &= b_1 \\
            a_{2, 1} x_1 + a{2, 2} x_2 + \cdots + a_{2, n} x_n &= b_2 \\
            \vdots &\phantom{}  \\
            a_{n, 1} x_1 + a{n, 2} x_2 + \cdots + a_{n, n} x_n &= b_n \\
        \end{array}
        \right.
    \end{equation}
    
    Then, the matrix of the \textit{coefficients} is denoted as $A$ with dimension $n \times n$ where
    \begin{equation}
        A = \begin{bmatrix}
            a_{1, 1} & a_{1, 2} & \dots  & a_{1, n} \\
            a_{2, 1} & a_{2, 2} & \dots  & a_{2, n} \\
            \vdots   & \vdots   & \ddots & \vdots   \\
            a_{n, 1} & a_{n, 2} & \dots & a_{n, n} \\
        \end{bmatrix}
    \end{equation}
    
    The \textit{unknowns} are denoted as $X$ with dimension $n \times 1$ where
    \begin{equation}
        X = \begin{bmatrix}
            x_1 \\
            x_2 \\
            \vdots \\
            x_n
        \end{bmatrix}
    \end{equation}
    
    The \textit{constants} are denoted as $B$ with dimension $n \times 1$ where
    \begin{equation}
        B = \begin{bmatrix}
            b_1 \\
            b_2 \\
            \vdots \\
            b_n
        \end{bmatrix}
    \end{equation}
    
    Together, they yield the matrix equation
    \begin{equation}
        A \cdot X = B
    \end{equation}
    To solve for $X$, one needs to find the \textit{inverse} matrix $\Inverse{A}$ of $A$ such that
    \begin{align}
        A \cdot X                   &= B \\
        \Inverse{A} \cdot A \cdot X &= \Inverse{A} \cdot B \\
        I \cdot X                   &= \Inverse{A} \cdot B \\
        X                           &= \Inverse{A} \cdot B
    \end{align}
    Where $I$ is the \textit{identity} matrix.
\end{definition}

\section{Gaussian Elimination}

\begin{definition}[Augmented Matrix]
    Given a system of linear equations
    \begin{equation}
        \left\{
        \begin{array}{c c}
            a_{1, 1} x_1 + a_{1, 2} x_2 + \cdots + a_{1, n} x_n &= b_1       \\
            a_{2, 1} x_1 + a_{2, 2} x_2 + \cdots + a_{2, n} x_n &= b_2       \\
            \vdots                                              &\phantom{}  \\
            a_{n, 1} x_1 + a_{n, 2} x_2 + \cdots + a_{n, n} x_n &= b_n       \\
        \end{array}
        \right.
    \end{equation}
    
    Then its \textit{augmented} matrix $A \vert B$ is
    \begin{equation}
        \begin{augmatrix}{4}
            a_{1, 1} & a_{1, 2} & \cdots & a_{1, n} & b_{1, n} \\
            a_{2, 1} & a_{2, 2} & \cdots & a_{2, n} & b_{2, n} \\
            \vdots   & \vdots   & \vdots & \ddots   & \vdots \\
            a_{n, 1} & a_{n, 2} & \cdots & a_{n, n} & b_{n, n} \\
        \end{augmatrix}
    \end{equation}
\end{definition}

\begin{definition}[Row Operations]\ \\
    \begin{enumerate}
        \item \textbf{Multiply and Add Row}
            \subitem Multiply row by scalar $\gamma$ then add the result to another row.
            \begin{equation}
                \det(A\prime) = \det(A)
            \end{equation}
        \item \textbf{Swap Rows}
            \begin{equation}
                \det(A\prime) = -\det(A)
            \end{equation}
        \item \textbf{Multiply Row}
            \subitem Multiply a row by scalar $\gamma$.
            \begin{equation}
                \det(A\prime) = \gamma \det(A)
            \end{equation}
    \end{enumerate}
\end{definition}

\begin{definition}[Gaussian Elimination]
    Using the \textit{row operations} applied to $A \vert B$ then one transforms $A X = B$ into an equivalent system
    \begin{equation}
        A\prime X = B\prime
    \end{equation}
    
    If it is the case that
    \begin{equation}
        A\prime = I
    \end{equation}
    
    Then there exists a \textit{solution} $X = B\prime$ to the system
    \begin{equation}
        B\prime = A\prime X = I X = X
    \end{equation}
\end{definition}

\begin{definition}[Inverse Matrix]
    The \textit{inverse} matrix $\Inverse{A}$ of $A$ is the matrix for which under multiplication yields the \textit{identity} matrix $I$
    \begin{equation}
        A \Inverse{A} \equiv \Inverse{A} A \equiv I
    \end{equation}
    
    With \textit{Gaussian Elimination} applied to $A \vert I$ then one transforms
    \begin{equation}
        A \Inverse{A} = I \Rightarrow A\prime \Inverse{A} = B\prime
    \end{equation}
    
    If
    \begin{equation}
        A\prime = I
    \end{equation}
    
    Then there exists a solution to $\Inverse{A} = B\prime$
    \begin{equation}
        B\prime = A\prime \Inverse{A} = I \Inverse{A} = \Inverse{A}
    \end{equation}
\end{definition}

\section{Linear Maps}

\begin{definition}[$\Real^{n}$]
    \begin{equation}
        \Real^{n} \coloneqq \overbrace{\Real \times \Real \times \cdots \times \Real}^{n}
    \end{equation}
\end{definition}

\begin{definition}[$\Real^{m, n}$]
    Is the domain of a matrix with $m$ rows and $n$ columns.
\end{definition}

\begin{lemma}[Linear Mapping and Matrices]
    Any matrix defines a linear mapping.
    
    Given a matrix $A \in \Real^{m, n}$, then $A$ defines a \textit{linear mapping} $f \colon \Real^{n} \to \Real^{m}$ if entries of $\Real^{n}$ are treated as \textit{column vectors} then for $V \in \Real^{n, 1}$
    \begin{equation}
        f(V) = A V
    \end{equation}
\end{lemma}

\begin{remark}
    For example, for the $\Real^{2, 3}$ matrix $A$ where
    \begin{equation}
        A = \begin{bmatrix}
            1 & 2 & 3 \\
            4 & 5 & 6
        \end{bmatrix} \in \Real^{2, 3}
    \end{equation}
    
    $A$ defines a \textit{linear mapping} $f$ such that
    \begin{equation}
        f \colon \Real^{3} \to \Real^{2}
    \end{equation}
    
    Since column vectors are used, then an $m \times n$ matrix defines a mapping from $\Real^{n} \to \Real^{m}$ with $m, n$ reversed.
    
    Then the mapping $f$ is defined as
    \begin{equation}
        f \begin{pmatrix}
            1 \\
            0 \\
            0 \\
        \end{pmatrix} = \begin{pmatrix}
            1 \\
            4
        \end{pmatrix} 
        \quad
        f \begin{pmatrix}
            0 \\
            1 \\
            0 \\
        \end{pmatrix} = \begin{pmatrix}
            2 \\
            5
        \end{pmatrix} 
        \quad
        f \begin{pmatrix}
            0 \\
            0 \\
            1 \\
        \end{pmatrix} = \begin{pmatrix}
            3 \\
            6
        \end{pmatrix} 
    \end{equation}
    
    Then the $i$th column of $A$ represents the image of the $i$th element of $\Real^{n, 1}$
\end{remark}

\begin{remark}
    Let there be an system of linear equations
    \begin{equation}
        \left\{
        \begin{array}{c}
            x\prime_1 = a_{1, 1} x_1 + a_{1, 2} x_2 + \cdots + a_{1, n} x_n \\
            x\prime_2 = a_{2, 1} x_1 + a_{2, 2} x_2 + \cdots + a_{2, n} x_n \\
            \vdots \\
            x\prime_n = a_{n, 1} x_1 + a_{n, 2} x_2 + \cdots + a_{n, n} x_n \\
        \end{array}
        \right.
    \end{equation}
    
    With
    \begin{equation}
        A = \begin{bmatrix}
            a_{1, 1} & a_{1, 2} & \cdots & a_{1, n} \\
            a_{2, 1} & a_{2, 2} & \cdots & a_{2, n} \\
            \vdots   & \vdots   & \ddots & \vdots   \\
            a_{n, 1} & a_{n, 2} & \cdots & a_{n, n} \\
        \end{bmatrix}
        \quad
        X = \begin{bmatrix}
            x_1    \\
            x_2    \\
            \vdots \\
            x_n    \\
        \end{bmatrix}
        \quad
        X\prime = \begin{bmatrix}
            x\prime_1 \\
            x\prime_2 \\
            \vdots    \\
            x\prime_n \\
        \end{bmatrix}
    \end{equation}
    
    Then there is a linear map
    \begin{equation}
        X\prime = A X
    \end{equation}
\end{remark}

\section{Eigenvalues and Eigenvectors}

\begin{definition}[Eigenvalue and Eigenvector]\ \\
    \begin{enumerate}
        \item A real number $\lambda \in \Real$ is an \textit{eigenvalue} of $A$
        \item A non-zero vector $\overrightarrow{\upsilon}$ is an \textit{eigenvector}
    \end{enumerate}
    If
    \begin{equation}
        A \overrightarrow{\upsilon} = \lambda \overrightarrow{\upsilon}, \overrightarrow{\upsilon} \ne \overrightarrow{0}
    \end{equation}
    
    Since
    \begin{equation}
        A \overrightarrow{\upsilon} - \lambda \overrightarrow{\upsilon} = (A - \lambda I) \cdot \overrightarrow{\upsilon} = \overrightarrow{0} \implies \lvert A - \lambda I \rvert = 0
    \end{equation}
    
    Hence, to solve for $\lambda$, use the equality
    \begin{equation}
        \lvert A - \lambda I \rvert = 0
    \end{equation}
\end{definition}

\begin{remark}
    An example.
    
    For the system of linear equations
    \begin{equation}
        \left\{
        \begin{array}{c}
            x\prime = 2 x + 2 y \\
            y\prime = 2 x + 5 y \\
        \end{array}
        \right.
    \end{equation}
    
    \begin{equation}
        A = \begin{bmatrix}
            2 & 2 \\
            2 & 5 \\
        \end{bmatrix}
    \end{equation}
    
    \begin{equation}
        \lvert A - \lambda I \rvert 
        =
        \begin{detmatrix}{2}
            2 - \lambda & 2           \\
            2           & 5 - \lambda \\
        \end{detmatrix}
        = \lambda^2 - 7 \lambda + 6 
        = 0
    \end{equation}
    
    Then there exist two \textit{eigenvalues}
    \begin{equation}
        \lambda^2 - 7 \lambda + 6 \implies \lambda_1 = 1, \lambda_2 = 6
    \end{equation}
    
    Then
    \begin{equation}
        A - \lambda_1 I = \begin{bmatrix}
            1 & 2 \\
            2 & 4 \\
        \end{bmatrix}
    \end{equation}
    
    And
    \begin{equation}
        A - \lambda_2 I = \begin{bmatrix}
            -4 & 2  \\
            2  & -1 \\
        \end{bmatrix}
    \end{equation}
    
    To find the \textit{eigenvector} associated with each \textit{eigenvalue}:
    
    \begin{enumerate}
        \item Case $\lambda_1 = 1$
            \subitem From the system, to find the \textit{eigenvector} ${\overrightarrow{\upsilon}}_{\lambda_1}$
            \begin{equation}
                (A - \lambda_1 I)
                \begin{bmatrix}
                    {\overrightarrow{\upsilon}}_{1} \\
                    {\overrightarrow{\upsilon}}_{2}
                \end{bmatrix}
                =
                \begin{bmatrix}
                    0 \\
                    0
                \end{bmatrix}
                \Rightarrow 
                \begin{bmatrix}
                    1 & 2 \\
                    2 & 4 \\
                \end{bmatrix}
                \begin{bmatrix}
                    {\overrightarrow{\upsilon}}_{1} \\
                    {\overrightarrow{\upsilon}}_{2}
                \end{bmatrix}
                =
                \begin{bmatrix}
                    0 \\
                    0
                \end{bmatrix}
            \end{equation}
            
            Via Gaussian elimination,
            \begin{equation}
                \Leftrightarrow 
                \begin{bmatrix}
                    1 & 2 \\
                    0 & 0 \\
                \end{bmatrix}
                \begin{bmatrix}
                    {\overrightarrow{\upsilon}}_{1} \\
                    {\overrightarrow{\upsilon}}_{2} \\
                \end{bmatrix}
                =
                \begin{bmatrix}
                    0 \\
                    0
                \end{bmatrix}
                \quad\quad \implies
                \left\{
                \begin{array}{l}
                    1 v_1 + 2 v_2 = 0 \\
                    0 + 0 = 0 \\
                \end{array}
                \right.
            \end{equation}
            
            Then there exists an \textit{infinite} number of solutions where
            \begin{equation}
                v_1 = -2 v_2
            \end{equation}
            
            Taking one of them is sufficient, e.g.
            \begin{equation}
                {\overrightarrow{\upsilon}}_{\lambda_1}
                = 
                \begin{bmatrix}
                    -2 \\
                    1  \\
                \end{bmatrix}
            \end{equation}
            
            Check that for the \textit{eigenvalue}-\textit{eigenvector} pair that
            \begin{equation}
                A {\overrightarrow{\upsilon}}_{\lambda_1} = \lambda_1 {\overrightarrow{\upsilon}}_{\lambda_1}
            \end{equation}
            \begin{equation}
                \begin{bmatrix}
                    2 & 2 \\
                    2 & 5 \\
                \end{bmatrix}
                \begin{bmatrix}
                    -2 \\
                    1 \\
                \end{bmatrix}
                =
                \begin{bmatrix}
                    -2 \\
                    1 \\
                \end{bmatrix}
                =
                \lambda_1
                \begin{bmatrix}
                    -2 \\
                    1 \\
                \end{bmatrix}
            \end{equation}
        \item Case $\lambda_2 = 6$
            \subitem Repeat the same procedure, and the \textit{eigenvector} takes the value
            \begin{equation}
                {\overrightarrow{\upsilon}}_{\lambda_2}
                = 
                \begin{bmatrix}
                    1 \\
                    2 \\
                \end{bmatrix}
            \end{equation}
    \end{enumerate}
\end{remark}

\begin{remark}
    With $A$ being symmetric, then \textit{eigenvectors} ${\overrightarrow{\upsilon}}_{\lambda_1}$ and ${\overrightarrow{\upsilon}}_{\lambda_2}$ are \textit{orthogonal}
    \begin{equation}
        \begin{bmatrix}
            {\overrightarrow{\upsilon}}_{\lambda_1} & {\overrightarrow{\upsilon}}_{\lambda_2}
        \end{bmatrix}
        \begin{bmatrix}
            {\overrightarrow{\upsilon}}_{\lambda_1} \\
            {\overrightarrow{\upsilon}}_{\lambda_2}
        \end{bmatrix}
        \equiv
        \overrightarrow{0}
    \end{equation}
\end{remark}

\begin{remark}
    For the system of linear equations
    \begin{equation}
        \left\{
        \begin{array}{l}
            x\prime = \frac{\sqrt{2}}{2} x + \frac{\sqrt{2}}{2} y  \\
            y\prime = -\frac{\sqrt{2}}{2} x + \frac{\sqrt{2}}{2} y \\
        \end{array}
        \right.
    \end{equation}
    
    \begin{equation}
        A = 
        \begin{bmatrix}
            \frac{\sqrt{2}}{2}  & \frac{\sqrt{2}}{2} \\
            -\frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} \\
        \end{bmatrix}
    \end{equation}
    
    \begin{equation}
        \lvert A - \lambda I \rvert
        =
        \begin{detmatrix}{2}
            \frac{\sqrt{2}}{2} - \lambda  & \frac{\sqrt{2}}{2}           \\
            -\frac{\sqrt{2}}{2}           & \frac{\sqrt{2}}{2} - \lambda \\
        \end{detmatrix}
        = \left( \frac{\sqrt{2}}{2} - \lambda \right)^2 + \frac{1}{2}
        = 0
    \end{equation}
    
    And thus there is no \textit{real} \textit{eigenvalues}; this $A$ is in fact a \textit{rotation}.
\end{remark}
